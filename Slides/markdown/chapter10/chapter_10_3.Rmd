---
title: Chapter 10.3 Hierarchical Beta-Binomial Modeling
author: Jim Albert and Monika Hu
date: Chapter 10 Bayesian Hierarchical Modeling
output: 
    beamer_presentation: default
    logo: ProbBayes_cover.jpg
fontsize: 12pt
---

```{r, echo = FALSE, warning = FALSE, message = FALSE}
library(ggplot2)
library(ProbBayes)
library(dplyr)
library(runjags)
library(coda)
library(reshape2)
library(ggridges)
crcblue <- "#2905a1"
```


## Example: Deaths after heart attack

- The New York State (NYS) Department of Health 

- Data on mortality after Acute Myocardial Infarction (AMI), commonly known as a heart attack

- The 2015 report: 13 hospitals in Manhattan, New York City

## Example: Deaths after heart attack cont'd

\footnotesize

| Hospital                                     | Cases | Deaths | Death % |
| :------------------------------------------- | ----: | -----: | ------: |
| Bellevue Hospital Ctr.                     |   129 |      4 |   3.101 |
| Harlem Hospital Ctr.                       |    35 |      1 |   2.857 |
| Lenox Hill Hospital                          |   228 |     18 |   7.894 |
| Metropolitan Hospital Ctr.                 |    84 |      7 |   8.333 |
| Mount Sinai Beth Israel                      |   291 |     24 |   8.247 |
| Mount Sinai Hospital                         |   270 |     16 |   5.926 |
| Mount Sinai Roosevelt                        |    46 |      6 |  13.043 |
| Mount Sinai St. Lukeâ€™s                       |   293 |     19 |   6.485 |
| NYU Hospitals Center                         |   241 |     15 |   6.224 |
| NYP Hospital - Allen Hospital                |   105 |     13 |  12.381 |
| NYP Hospital - Columbia Presbyterian Ctr.  |   353 |     25 |   7.082 |
| NYP Hospital - New York Weill Cornell Ctr. |   250 |     11 |   4.400 |
| NYP/Lower Manhattan Hospital                 |    41 |      4 |   9.756 |


## A hierarchical Beta-Binomial model


- Treat "cases" as trials and "deaths" as successes: the Binomial sampling model

- The objective is to learn about the death probability $p$ of the hospitals

- Data shows that some hospitals have much higher death rates than other hospitals

- Separate estimates? Combined estimates?

\pause

- A hierarchical model!

## Model specification


- $Y_i$: the number of resulted deaths from heart attack

- $n_i$: the number of heart attack cases

- $p_i$: the death rate for hospital $i$

\pause

- Sampling, for $i, \cdots, 13$:
\begin{equation}
Y_i \sim \textrm{Binomial}(n_i, p_i)
\end{equation}

- Prior for $p_i$, $i = 1, \cdots, 13$:
\begin{equation}
p_i \sim \textrm{Beta}(a, b)
\end{equation}

- Review:
\begin{equation}
p_i \mid y_i \sim \textrm{Beta}(a + y_i, b + n_i - y_i)
\end{equation}

## Model specification cont'd

- Sampling, for $i, \cdots, 13$:
\begin{equation}
Y_i \sim \textrm{Binomial}(n_i, p_i)
\end{equation}

- Prior for $p_i$, Stage1: for $i = 1, \cdots, 13$:
\begin{equation}
p_i \sim \textrm{Beta}(a, b)
\end{equation}

- Prior for $p_i$, Stage 2: the hyperprior:
\begin{eqnarray}
a, b \sim \pi(a, b)
\end{eqnarray}


## Graphical representations of the hierarchical model

```{r, echo = FALSE, out.width = 360} 
knitr::include_graphics("figures/treediagram2.png")
```

## Another hierarchical model

- If the beta parameters $a$ and $b$ are known constants

```{r, echo = FALSE, out.width = 360} 
knitr::include_graphics("figures/treediagram3.png")
```

## Separate estimates model

```{r, echo = FALSE, out.width = 300}
knitr::include_graphics("figures/treediagram4.png")
```


## Beta prior revisit

- Review from Chapter 7
    - ```beta.select()``` function for choosing $a$ and $b$
    - The parameter $a$ as the prior count of "successes"
    - The parameter $b$ as the prior count of "failures"
    - The sum $a + b$ represents the prior sample size
    - The expectation of Beta(a, b) is $\frac{a}{a + b}$
    
\pause

- A natural parameterization
    - $\pi(\mu, \eta)$
    - $\mu = \frac{a}{a+b}$: mean
    - $\eta = a + b$: (prior) sample size

\begin{equation}
\mu, \eta \sim \pi(\mu, \eta)
\end{equation}
where $a = \mu\eta$ and $b = (1-\mu)\eta$

## Second-stage prior

- Assume $\mu$ and $\eta$ are independent

- The hyperprior expectation $\mu$ is the mean measure for $p_i$, the average death rate across 13 hospitals
    - if we have little prior knowledge about the expectation $\mu$, we can assign a uniform prior (Beta(1, 1))

\pause

- Consider known hyperparameter values

\begin{equation}
E(p^* \mid y^*) = \frac{y^* + \mu \eta }{n^* + \eta}
\end{equation}

## Second-stage prior cont'd

- The posterior mean is rewritten as
\begin{equation}
E(p^* \mid y^*) = (1 - \lambda) \frac{y^*}{n^*} + \lambda \mu
\end{equation}
    - $\lambda$ is the shrinkage fraction $\lambda = \frac{\eta}{n^* + \eta}$

- $\lambda$ falls in the interval (0, 1) and represents the degree of shrinkage of the posterior mean away from the sample proportion $y^* / n^*$ towards the prior mean $\mu$

## Second-stage prior cont'd

- Suppose we believe *a priori* that, for a representative sample size $n^*$, the shrinkage $\lambda$ is Uniform(0, 1)

- The prior density for the prior sample size $\eta$ has the form
\begin{equation}
\pi(\eta) = \frac{n^*}{(n^* + \eta)^2}, \, \, \eta > 0
\end{equation}

- The logarithm of $\eta$, $\theta = \log \eta$, has a Logistic distribution with location $\log n^*$ and scale 1
\begin{equation}
\pi(\theta) = \frac{e^{-(\theta - \log n^*)}}
{(1 + e^{-(\theta - \log n^*)})^2}
\end{equation}


## Model specification

- Sampling, for $i, \cdots, 13$:
\begin{equation}
Y_i \sim \textrm{Binomial}(n_i, p_i)
\end{equation}

- Prior for $p_i$, Stage 1: for $i = 1, \cdots, 13$:
\begin{equation}
p_i \sim \textrm{Beta}(a, b)
\end{equation}

- Prior for $p_i$, Stage 2:
\begin{eqnarray}
\mu &\sim& \textrm{Beta}(1, 1), \label{eq:BetaBinomialHyperprior_v21}\\
\log \eta &\sim& \textrm{Logistic}(\log n^*, 1)
\end{eqnarray}
where $a = \mu\eta$ and $b = (1-\mu)\eta$

## JAGS step 1: describe the model by a script

```{r size = "footnotesize"}
modelString <-"
model {
## likelihood
for (i in 1:N){
   y[i] ~ dbin(p[i], n[i])
}
## priors and hyperpriors
for (i in 1:N){
   p[i] ~ dbeta(a, b)
}
a <- mu*eta
b <- (1-mu)*eta
mu ~ dbeta(mua, mub)
eta <- exp(logeta)
logeta ~ dlogis(logn, 1)
}
"
```

## JAGS step 2: define the data and prior parameters

```{r size = "footnotesize"}
deathdata <- read.csv("DeathDataset.csv", header=T)
deathdata$DeathRatio <- deathdata$Deaths / 
  deathdata$Cases*100

y <- deathdata$Deaths     
n <- deathdata$Cases      
N <- length(y) 
the_data <- list("y" = y, "n" = n, "N" = N, 
                 "mua" = 1, "mub" = 1, 
                 "logn" = log(100))
```

## JAGS step 2: define the data and prior parameters cont'd


```{r message = FALSE, size = "footnotesize", warning = FALSE, results = 'hide'}
posterior <- run.jags(modelString,
                      n.chains = 1,
                      data = the_data,
                      monitor = c("p", "mu", "logeta"),
                      adapt = 1000,
                      burnin = 5000,
                      sample = 5000)
```


## MCMC diagnostics and summarization

```{r, fig.height = 3, fig.width = 4.5}
plot(posterior, vars = "logeta")
```

## MCMC diagnostics and summarization cont'd

```{r message = FALSE, warning = FALSE, echo = FALSE}
print(posterior, digits = 3)
```

## Inferences

- Pooling / shrinkage effects

```{r, fig.height = 3, fig.width = 4.5, echo = FALSE}
Post_Means <- summary(posterior)[, 4]

Means1 <- data.frame(Type = "Sample", Mean = deathdata$DeathRatio/100)
Means2 <- data.frame(Type = "Posterior", Mean =
                       Post_Means[1:13])

Means1$Hospital <- 1:13
Means2$Hospital <- 1:13
ggplot(rbind(Means1, Means2),
       aes(Type, Mean, group = Hospital)) +
  geom_line(color = crcblue) +
  geom_point(size = 1) +
  increasefont(Size = 10) +
  ylab("Proportion") +
  annotate(geom = "text",
           x = 0.75, y = .125,
           label = "NYP - Allen", size = 3) +
  annotate(geom = "text",
           x = 0.75, y = .135,
           label = "Mt. Sinai Roos.", size = 3)

```

## Inferences

- Posterior densities
```{r, fig.height = 3, fig.width = 4.5, echo = FALSE, warning = FALSE}
p_draws <- as.mcmc(posterior, vars = "p")

df = as.data.frame(cbind(seq(1:5000), p_draws))
df_long = melt(df, id.vars = "V1")


ggplot(df_long, aes(x = value, y = variable)) +
  geom_density_ridges() +
  theme_grey(base_size = 10, base_family = "") +
  xlim(0, .15)
```

## Inferences

- Comparison of hospitals
    - e.g. compare the death rates of two hospitals directly

```{r size = "footnotesize"}
p11draws <- as.mcmc(posterior, vars = "p[11]")
p12draws <- as.mcmc(posterior, vars = "p[12]")
diff = p11draws - p12draws
sum(diff > 0)/5000
```

## Inferences

- Comparison of hospitals
    - e.g. ranking
\begin{equation}
P(p_1 < p_2, ..., p_1 < p_{13} \mid y)
\end{equation}

```{r, fig.height = 2.4, fig.width = 4, echo = FALSE, warning = FALSE}
df = as.data.frame(diff)
df_long %>%
  group_by(V1) %>%
  mutate(Ranks = rank(value)) -> rank_data

rank_data %>%
  filter(variable == "p[1]")  %>%
  group_by(Ranks) %>%
  summarize(Count = n(),
            Proportion = Count / 5000,
            .groups = "drop")  %>%
  mutate(Type = "Bellevue Hospital Center") -> R1
rank_data %>%
  filter(variable == "p[2]")  %>%
  group_by(Ranks) %>%
  summarize(Count = n(),
            Proportion = Count / 5000,
             .groups = "drop")  %>%
  mutate(Type = "Harlem Hospital Center") -> R2

ggplot(rbind(R1, R2), aes(Ranks, Proportion)) +
  geom_col(fill = crcblue) +
  facet_wrap(~ Type, ncol = 1) +
  increasefont(Size = 10) +
  xlab("Rank") + ylab("Probability")
```

## Inferences

- Comparison of hospitals
    - e.g. probability of rank 1

```{r, fig.height = 2.8, fig.width = 4.5, echo = FALSE, warning = FALSE}
rank_data %>%
  filter(Ranks == 1) -> rank1

rank1 %>% group_by(variable) %>%
  summarize(N = n(), .groups = "drop") %>%
        mutate(Probability = N / sum(N),
               Hospital = deathdata$Hospital) -> S_rank1

S_rank1$Hosp <- c("Bellevue", "Harlem", "Lenox Hill",
                  "Metropolitan", "Mount Sinai Beth Israel",
                  "Mount Sinai", "Mount Sinai Rossevelt",
                  "Mount Sinai St. Luke's",
                  "NYU", "NYP - Allen",
                  "NYP - Columbia", "NYP - NY Weill Corner",
                  "NYP - Lower Manhattan")

ggplot(S_rank1,
       aes(reorder(Hosp, Probability), Probability)) +
  geom_point(size = 2, color = crcblue) +
  coord_flip() +
  increasefont(Size = 10) +
  xlab("Hospital")
```
