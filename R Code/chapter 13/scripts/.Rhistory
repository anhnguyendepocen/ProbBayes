"mu1" = 0, "g1" = 0.0001,
"a" = 1, "b" = 1)
y <- house_prices$price
x <- house_prices$size / 1000
N <- length(y)
the_data <- list("y" = y, "x" = x, "N" = N,
"mu0" = 0, "g0" = 0.0001,
"mu1" = 0, "g1" = 0.0001,
"a" = 1, "b" = 1)
initsfunction <- function(chain){
.RNG.seed <- c(1,2)[chain]
.RNG.name <- c("base::Super-Duper",
"base::Wichmann-Hill")[chain]
return(list(.RNG.seed=.RNG.seed,
.RNG.name=.RNG.name))
}
posterior <- run.jags(modelString,
n.chains = 1,
data = the_data,
monitor = c("beta0",
"beta1", "sigma"),
adapt = 1000,
burnin = 5000,
sample = 5000,
inits = initsfunction)
library(runjags)
posterior <- run.jags(modelString,
n.chains = 1,
data = the_data,
monitor = c("beta0",
"beta1", "sigma"),
adapt = 1000,
burnin = 5000,
sample = 5000,
inits = initsfunction)
post <- as.data.frame(as.mcmc(posterior))
str(post)
X1 <- matrix(c(1, 1, 1, 2), 2, 2, byrow = TRUE)
X1
theta.sample <- post
d = dim(X1)
n1 = d[1]
m = length(theta.sample$sigma)
m1 = array(0, c(m, n1))
for (j in 1:n1) {
m1[, j] = t(X1[j, ] %*% t(theta.sample$beta))
}
m
m <- nrow(theta.sample)
m
post1 <- select(post, -sigma)
head(post1)
d <- dim(X1)
n1 <- d[1]
m <- nrow(theta.sample)
m1 <- array(0, c(m, n1))
theta.sample %>% select(-sigma) %>%
as.matrix() -> theta.sample
for (j in 1:n1) {
m1[, j] <- t(X1[j, ] %*% t(theta.sample))
}
str(m1)
str(posterior)
names(post)
posterior %>%
as.mcmc() %>%
as.data.frame %>%
mutate(exp_1 = beta0 + beta1,
exp_2 = beta0 + beta2) %>%
select(exp_1, exp_2) -> LP
posterior %>%
as.mcmc() %>%
as.data.frame %>%
mutate(exp_1 = beta0 + beta1,
exp_2 = beta0 + 2 * beta1) %>%
select(exp_1, exp_2) -> LP
head(LP)
blinregpred
posterior %>%
posterior %>%
as.mcmc() %>%
as.data.frame %>%
mutate(N <- nrow(),
pred_1 = rnorm(N, beta0 + beta1, sigma)
pred_2 = rnorm(N, beta0 + 2 * beta1, sigma)) %>%
select(pred_1, pred_2) -> LP
posterior %>%
as.mcmc() %>%
as.data.frame %>%
mutate(N = nrow(),
pred_1 = rnorm(N, beta0 + beta1, sigma)
pred_2 = rnorm(N, beta0 + 2 * beta1, sigma)) %>%
select(pred_1, pred_2) -> LP
dim(post)
posterior %>%
as.mcmc() %>%
as.data.frame %>%
mutate(pred_1 = rnorm(5000, beta0 + beta1, sigma)
pred_2 = rnorm(5000, beta0 + 2 * beta1, sigma)) %>%
select(pred_1, pred_2) -> PRED
posterior %>%
as.mcmc() %>%
as.data.frame() %>%
mutate(exp_1 = beta0 + beta1,
exp_2 = beta0 + 2 * beta1) %>%
select(exp_1, exp_2) -> LP
posterior %>%
as.mcmc() %>%
as.data.frame() %>%
mutate(pred_1 = rnorm(5000, beta0 + beta1, sigma)
pred_2 = rnorm(5000, beta0 + 2 * beta1, sigma)) %>%
select(pred_1, pred_2) -> PRED
posterior %>%
as.mcmc() %>%
as.data.frame() %>%
mutate(pred_1 = rnorm(5000, beta0 + beta1, sigma),
pred_2 = rnorm(5000, beta0 + 2 * beta1, sigma)) %>%
select(pred_1, pred_2) -> PRED
apply(LP, 2, quantile, .95)
apply(PRED, 2, quantile, .95)
posterior %>%
as.mcmc() %>%
as.data.frame() %>%
mutate(N = nrow(),
pred_1 = rnorm(N, beta0 + beta1, sigma),
pred_2 = rnorm(N, beta0 + 2 * beta1, sigma)) %>%
select(pred_1, pred_2) -> PRED
posterior %>%
as.mcmc() %>%
as.data.frame() %>%
mutate(N = length(sigma),
pred_1 = rnorm(N, beta0 + beta1, sigma),
pred_2 = rnorm(N, beta0 + 2 * beta1, sigma)) %>%
select(pred_1, pred_2) -> PRED
posterior %>%
mcmc() %>%
as.data.frame() %>%
mutate(exp_1 = beta0 + beta1,
exp_2 = beta0 + 2 * beta1) %>%
select(exp_1, exp_2) -> LP
posterior %>%
as.mcmc() %>%
as.data.frame() %>%
mutate(exp_1 = beta0 + beta1,
exp_2 = beta0 + 2 * beta1) %>%
select(exp_1, exp_2) -> LP
apply(post, 2, quantile, c(.05, .95))
head(LP)
?spread
??spread
?pivot_longer
??pivot_longer
library(tidyr)
LP %>%
pivot_longer(exp_1-exp_2) ->  LP2
LP %>%
pivot_longer(starts_with(exp)) ->  LP2
LP %>%
pivot_longer(starts_with(exp), Expected) ->  LP2
anscombe
anscombe %>%
pivot_longer(everything(),
names_to = c(".value", "set"),
names_pattern = "(.)(.)"
)
LP %>%
pivot_longer(everything(),
names_to = c(".value", "set")) ->  LP2
LP %>%
pivot_longer(everything(),
names_to = c(".value", "set"),
names_pattern = "(.)(.)") ->  LP2
head(LP)
head(LP2)
vignette("pivot")
head(LP)
LP %>%
pivot_longer(cols = starts_with("exp"),
names_to = "covariate",
values_to = "predicted") ->  LP2
head(LP2)
LP %>%
pivot_longer(cols = starts_with("exp"),
names_to = "covariate",
values_to = "predicted",
values_drop_na = TRUE) ->  LP2
head(LP2)
ggplot(LP2, aes(covariate, predicted)) +
geom_density()
ggplot(LP2, aes(covariate, y = predicted)) +
geom_density()
ggplot(LP2, aes(y = predicted)) +
geom_density() +
facet_wrap(~ covariate)
ggplot(LP2, aes(predicted)) +
geom_density() +
facet_wrap(~ covariate)
ggplot(LP2, aes(predicted)) +
geom_density() +
facet_wrap(~ covariate, ncol = 1)
apply(LP, 2, quantile, c(0.05, 0.95))
library(ggridges)
?ggridges
head(LP2)
ggplot(LP2, aes(predicted, covariate)) +
geom_density_ridges()
ggplot(LP2, aes(predicted, covariate)) +
geom_density_ridges(span = 1)
ggplot(LP2, aes(predicted, covariate)) +
geom_density_ridges(width = 1)
?geom_density_ridges
ggplot(LP2, aes(predicted, covariate)) +
geom_density_ridges() +
theme_ridges()
ggplot(LP2, aes(predicted, covariate)) +
geom_density_ridges(bw = 1) +
theme_ridges()
ggplot(LP2, aes(predicted, covariate)) +
geom_density_ridges(adjust = 0.5) +
theme_ridges()
ggplot(LP2, aes(predicted, covariate)) +
geom_density_ridges() +
theme_ridges()
head(post)
the_data
post[1,]
post %>% sample(1)
?sample_n
post %>%
sample_n(size = 1)
y
x
N
post %>%
sample_n(size = 1) %>%
mutate(yrep = rnorm(N, beta0 + beta1 * x, sigma))
rep_data <- function(post, x){
post %>%
sample_n(size = 1) -> post_s
data.frame(x = x,
y = rnorm(length(x),
post_s$beta0 + post_s$beta1 * x,
post_s$sigma))
}
rep_data(post, x)
library(corpus)
library(tidytext)
library(dplyr)
library(purrr)
library(ggplot2)
library(CalledStrike)
library(coda)
?federalist
federalist[1.]
federalist[1,]
View(federalist)
federalist[1, 'text']
library(ProbBayes)
head(football_field_goals)
?football_field_goals
head(football_field_goals)
JAGS_normal
View(animation_ratings)
setwd("~/Dropbox/BAYES BOOK/FINAL CODE & DATA/chapter 13/scripts")
source("get_onbase_data.R")
d <- get_onbase_data((1978, 1000))
d <- get_onbase_data(1978, 1000)
d <- get_onbase_data(1978, 1000)
head(d)
compute_individual_regressions <- function(d1){
library(tidyverse)
library(broom)
regressions <- d1 %>%
split(pull(., nameLast)) %>%
map(~ glm(cbind(OB, PA - OB) ~ AgeD +
I(AgeD ^ 2),
family = binomial, data = .)) %>%
map_df(tidy, .id = "Name") %>%
as_tibble() %>% select(Name, term, estimate)
# compute predicted probabilities for all seasons and players
regressions %>% spread(term, estimate) -> regs
names(regs) <- c("Name", "B0", "B1", "B2")
inner_join(d1, regs, by=c("nameLast"="Name")) -> d1
d1 %>%
mutate(LP = B0 + B1 * AgeD +
B2 * AgeD ^ 2,
P = exp(LP) / (1 + exp(LP))) -> d1
d1
}
"source(compute_individual_regressions.R)"
source("compute_individual_regressions.R")
d <- compute_individual_regressions(d)
head(d)
names(d)
source("mlm_regression.R")
d <- mlm_regression(d)
mlm_regression <- function(d1){
require(runjags)
require(tidyverse)
modelString = "
model {
for (i in 1:N){
y[i] ~ dbin(p[i], n[i])
logit(p[i]) <- a[player[i]] + b[player[i]] * (x[i] - 30) +
c[player[i]] * (x[i] - 30) * (x[i] - 30)
}
for (j in 1:J){
a[j] <- B[j,1]
b[j] <- B[j,2]
c[j] <- B[j,3]
B[j,1:3] ~ dmnorm (mu.beta[], Tau.B[,])
}
mu.beta[1:3] ~ dmnorm(mean[1:3],prec[1:3 ,1:3 ])
Tau.B[1:3 , 1:3] ~ dwish(Omega[1:3 ,1:3 ], 3)
}
"
# data for JAGS
b.data <- list(y = d1$OB,
x = d1$Age,
player = d1$Player,
n = d1$PA,
N = dim(d1)[1],
J = max(d1$Player),
mean = c(0, 0, 0),
Omega = diag(c(.1,.1,.1)),
prec = diag(c(1.0E-6,1.0E-6,1.0E-6)))
# implement MCMC
posterior <- run.jags(modelString,
n.chains = 1,
data = b.data,
monitor = c("B", "mu.beta"),
adapt = 1000,
burnin = 5000,
sample = 20000)
post <- as.mcmc(posterior)
post <- as.data.frame(post)
# compute posterior means, use these to get estimated
# probabilities
est <- apply(post, 2, mean)[1:(3 * b.data$J)]
est <- as.data.frame(matrix(est, b.data$J, 3, byrow = FALSE))
names(est) <- c("b0", "b1", "b2")
est$Player <- 1:b.data$J
d1 <- inner_join(d1, est)
d1 %>% mutate(lp = b0 + b1 * (Age - 30) +
b2 * (Age - 30) ^ 2,
p = exp(lp) / (1 + exp(lp)))
d1
}
d <- mlm_regression(d)
d[1,]
d <- compute_individual_regressions(d)
d78 <- get_onbase_data(1978, 1000)
d78_b <- compute_individual_regressions(d78)
names(d78_b)
d78_c <- mlm_regression(d78)
names(d78_c)
d78_c <- mlm_regression(d78)
mlm_regression <- function(d1){
require(runjags)
require(tidyverse)
require(coda)
modelString = "
model {
for (i in 1:N){
y[i] ~ dbin(p[i], n[i])
logit(p[i]) <- a[player[i]] + b[player[i]] * (x[i] - 30) +
c[player[i]] * (x[i] - 30) * (x[i] - 30)
}
for (j in 1:J){
a[j] <- B[j,1]
b[j] <- B[j,2]
c[j] <- B[j,3]
B[j,1:3] ~ dmnorm (mu.beta[], Tau.B[,])
}
mu.beta[1:3] ~ dmnorm(mean[1:3],prec[1:3 ,1:3 ])
Tau.B[1:3 , 1:3] ~ dwish(Omega[1:3 ,1:3 ], 3)
}
"
# data for JAGS
b.data <- list(y = d1$OB,
x = d1$Age,
player = d1$Player,
n = d1$PA,
N = dim(d1)[1],
J = max(d1$Player),
mean = c(0, 0, 0),
Omega = diag(c(.1,.1,.1)),
prec = diag(c(1.0E-6,1.0E-6,1.0E-6)))
# implement MCMC
posterior <- run.jags(modelString,
n.chains = 1,
data = b.data,
monitor = c("B", "mu.beta"),
adapt = 1000,
burnin = 5000,
sample = 20000)
post <- as.mcmc(posterior)
post <- as.data.frame(post)
# compute posterior means, use these to get estimated
# probabilities
est <- apply(post, 2, mean)[1:(3 * b.data$J)]
est <- as.data.frame(matrix(est, b.data$J, 3, byrow = FALSE))
names(est) <- c("b0", "b1", "b2")
est$Player <- 1:b.data$J
d1 <- inner_join(d1, est)
d1 %>% mutate(lp = b0 + b1 * (Age - 30) +
b2 * (Age - 30) ^ 2,
p = exp(lp) / (1 + exp(lp)))
d1
}
d78_c <- mlm_regression(d78)
names(d78_c)
mlm_regression <- function(d1){
require(runjags)
require(tidyverse)
require(coda)
modelString = "
model {
for (i in 1:N){
y[i] ~ dbin(p[i], n[i])
logit(p[i]) <- a[player[i]] + b[player[i]] * (x[i] - 30) +
c[player[i]] * (x[i] - 30) * (x[i] - 30)
}
for (j in 1:J){
a[j] <- B[j,1]
b[j] <- B[j,2]
c[j] <- B[j,3]
B[j,1:3] ~ dmnorm (mu.beta[], Tau.B[,])
}
mu.beta[1:3] ~ dmnorm(mean[1:3],prec[1:3 ,1:3 ])
Tau.B[1:3 , 1:3] ~ dwish(Omega[1:3 ,1:3 ], 3)
}
"
# data for JAGS
b.data <- list(y = d1$OB,
x = d1$Age,
player = d1$Player,
n = d1$PA,
N = dim(d1)[1],
J = max(d1$Player),
mean = c(0, 0, 0),
Omega = diag(c(.1,.1,.1)),
prec = diag(c(1.0E-6,1.0E-6,1.0E-6)))
# implement MCMC
posterior <- run.jags(modelString,
n.chains = 1,
data = b.data,
monitor = c("B", "mu.beta"),
adapt = 1000,
burnin = 5000,
sample = 20000)
post <- as.mcmc(posterior)
post <- as.data.frame(post)
# compute posterior means, use these to get estimated
# probabilities
est <- apply(post, 2, mean)[1:(3 * b.data$J)]
est <- as.data.frame(matrix(est, b.data$J, 3, byrow = FALSE))
names(est) <- c("b0", "b1", "b2")
est$Player <- 1:b.data$J
d1 <- inner_join(d1, est)
d1 %>% mutate(lp = b0 + b1 * (Age - 30) +
b2 * (Age - 30) ^ 2,
p = exp(lp) / (1 + exp(lp)))  -> d1
d1
}
d78_c <- mlm_regression(d78)
head(d78_c)
library(brms)
names(d)
fit <- brm(OB | trials(PA) ~ AgeD + I(AgeD ^ 2) +
(AgeD + I(AgeD ^  2) | Player),
data = d78,
family = binomial("logit"))
sum(d$PA == 0)
d78_new <- filter(d78, PA > 0)
fit <- brm(OB | trials(PA) ~ AgeD + I(AgeD ^ 2) +
(AgeD + I(AgeD ^  2) | Player),
data = d78_new,
family = binomial("logit"))
posterior_sims <- posterior_samples(fit)
names(posterior_sims)
apply(posterior_sims[, 1:3], 2, mean)
fit2 <- brm(OB | trials(PA) ~
(AgeD + I(AgeD ^  2) | Player),
data = d78_new,
family = binomial("logit"))
library(pscl)
library(brms)
library(tidyverse)
library(BApredict)
library(TeachBayes)
library(runjags)
library(bayesplot)
library(coda)
select(EfronMorris, name, r) %>%
mutate(n = 45) -> d
fit <- brm(data = d, family = binomial,
r | trials(n) ~ 1 + (1 | name),
prior = c(prior(normal(0, 2), class = Intercept),
prior(cauchy(0, 1), class = sd)),
iter = 20000)
post <- posterior_samples(fit)
post[1,]
plogis(-0.93751)
mean(d$r)/45
coef(fit)
apply(post, 2, mean)
fit <- brm(OB | trials(PA) ~ AgeD + I(AgeD ^ 2) +
(AgeD + I(AgeD ^  2) | Player),
data = d78_new,
family = binomial("logit"))
coef(fit)
