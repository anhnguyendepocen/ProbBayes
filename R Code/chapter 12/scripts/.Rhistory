coinflips <- rbernoulli(585, 0.0786)
ofers <- get_streaks(1 - coinflips)
sd(ofers)
myfunction <- function(){
coinflips <- rbernoulli(585, 0.0786)
ofers <- get_streaks(1 - coinflips)
sd(ofers)
}
SD <- replicate(100, myfunction())
hist(SD)
abline(v = mt_streak)
hist(SD)
abline(v = mt_streak, col = "red")
?dcauchy
?laplace
knitr::opts_chunk$set(echo = TRUE,
message = FALSE)
y <- c(10, 12, 13, 15, 25, 30, 26, 29)
myposterior <- function(theta, y){
mu <- theta[1]
sigma <- theta[2]
sum(dcauchy(y, theta, sigma,
log = TRUE)) +
dnorm(theta, 0, 100, log = TRUE) +
dgamma(sigma, shape = 1, rate = 1,
log = TRUE)
}
library(ProbBayes)
mycontour(myposterior,
c(-10, 45, .1, 16),
y)
laplace(myposterior, c(20, 7), y)
myposterior <- function(theta, y){
mu <- theta[1]
sigma <- theta[2]
sum(dcauchy(y, theta, sigma,
log = TRUE)) +
dnorm(mu, 0, 100, log = TRUE) +
dgamma(sigma, shape = 1, rate = 1,
log = TRUE)
}
library(ProbBayes)
mycontour(myposterior,
c(-10, 45, .1, 16),
y)
laplace(myposterior, c(20, 7), y)
install.packages(c("data.table", "fields", "stringdist"))
library(ggmap)
install.packages("ggmap")
register_google(key = "AIzaSyDPj6jhf3CS6mgIYx3Of6EdXykG-PbD-74")
library(ggmap)
register_google(key = "AIzaSyDPj6jhf3CS6mgIYx3Of6EdXykG-PbD-74")
register_google(key = "AIzaSyDPj6jhf3CS6mgIYx3Of6EdXykG-PbD-74", write = TRUE)
hdf <- get_map("houston, texas")
ggmap(hdf, extent = "normal")
(map <- get_map(c(-97.14667, 31.5493)))
(map <- get_googlemap(c(-97.14667, 31.5493)))
m <- get_openstreetmap()
m <- get_stamenmap()
ggmap(m)
ggmap(get_stamenmap(c(-100, 30, -90, 35)))
m <- get_googlemap()
m <-  get_googlemap("Toledo, OH")
(map <- get_googlemap(c(-97.14667, 31.5493)))
map<-get_map(location='united states', zoom=4, maptype = "terrain",
source='google',color='color')
chi_bb <- c(left = -87.936287,
bottom = 41.679835,
right = -87.447052,
top = 42.000835)
chicago_stamen <- get_stamenmap(bbox = chi_bb,
zoom = 11)
chicago_stamen
ggmap(chicago_stamen)
library(ggmap)
chi_bb <- c(left = -87.936287,
bottom = 41.679835,
right = -87.447052,
top = 42.000835)
chicago_stamen <- get_stamenmap(bbox = chi_bb,
zoom = 11)
chicago_stamen
ggmap(chicago_stamen)
187*.58
15.59 + 27 + 13.10 + 24.59
15.59 + 27 + 13.10 + 24.59 + 308.60 + 108.46
twn <- read.table("http://personal.bgsu.edu/~mrizzo/Rx/Rx-data/twins.dat.txt",
header=TRUE,
sep=",", na.strings=".")
c.age <- cut(twn$AGE, c(0, 30, 40, 50, 100))
c.wage <- cut(twn$HRWAGEL, c(0, 7, 13, 20, 150))
age.wage.table <- table(c.age, c.wage)
T1 <- prop.table(age.wage.table, 1)
plot(T1)  # mosaic plot
barplot(t(T1), beside=T, legend.text=dimnames(T1)$c.wage,
args.legend=list(x="topright"), ylab="PROPORTION",
xlab="AGE GROUP")
S <- chisq.test(age.wage.table)
S
S$residuals
mosaicplot(age.wage.table, shade=TRUE)
die1 <- sample(6, 1000, replace=TRUE)
die2 <- sample(6, 1000, replace=TRUE)
max.rolls <- pmax(die1, die2)
sum.rolls <- die1 + die2
T1 <- table(max.rolls, sum.rolls)
T1
prop.table(T1, 1)
pidigits =
read.table("http://www.itl.nist.gov/div898/strd/univ/data/PiDigits.dat",
skip=60)
T1 <- table(pidigits)
T1
barplot(T1)
chisq.test(T1)
with(cars, plot(speed, dist))
with(cars, plot(speed, dist,
xlab="Speed (mpg)",
ylab="Stopping Distance (feet)"))
with(cars, plot(speed, dist,
xlab="Speed (mpg)",
ylab="Stopping Distance (feet)",
col="red", pch=17))
library(LearnBayes)
?bfexch
install.packages(c("cowplot", "googleway", "ggplot2", "ggrepel",
"ggspatial", "libwgeom", "sf", "rnaturalearth", "rnaturalearthdata")
0
install.packages(c("cowplot", "googleway", "ggplot2", "ggrepel",
"ggspatial", "libwgeom", "sf", "rnaturalearth", "rnaturalearthdata")
)
install.packages("libwgeom")
install.packages("lwgeom")
library("ggplot2")
theme_set(theme_bw())
library("sf")
library("rnaturalearth")
library("rnaturalearthdata")
world <- ne_countries(scale = "medium", returnclass = "sf")
install.packages("rgeos")
world <- ne_countries(scale = "medium", returnclass = "sf")
class(world)
ggplot(data = world) +
geom_sf()
ggplot(data = world) +
geom_sf() +
xlab("Longitude") + ylab("Latitude") +
ggtitle("World map", subtitle = paste0("(", length(unique(world$NAME)), " countries)"))
ggplot(data = world) +
geom_sf(color = "black", fill = "lightgreen")
ggplot(data = world) +
geom_sf(aes(fill = pop_est)) +
scale_fill_viridis_c(option = "plasma", trans = "sqrt")
ggplot(data = world) +
geom_sf() +
coord_sf(crs = "+proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000 +ellps=GRS80 +units=m +no_defs ")
ggplot(data = world) +
geom_sf() +
coord_sf(xlim = c(-102.15, -74.12), ylim = c(7.65, 33.97), expand = FALSE)
library("ggspatial")
ggplot(data = world) +
geom_sf() +
annotation_scale(location = "bl", width_hint = 0.5) +
annotation_north_arrow(location = "bl", which_north = "true",
pad_x = unit(0.75, "in"), pad_y = unit(0.5, "in"),
style = north_arrow_fancy_orienteering) +
coord_sf(xlim = c(-102.15, -74.12), ylim = c(7.65, 33.97))
ggplot(data = world) +
geom_sf() +
geom_text(data= world_points,aes(x=X, y=Y, label=name),
color = "darkblue", fontface = "bold", check_overlap = FALSE) +
annotate(geom = "text", x = -90, y = 26, label = "Gulf of Mexico",
fontface = "italic", color = "grey22", size = 6) +
coord_sf(xlim = c(-102.15, -74.12), ylim = c(7.65, 33.97), expand = FALSE)
library("sf")
world_points<- st_centroid(world)
world_points <- cbind(world, st_coordinates(st_centroid(world$geometry)))
ggplot(data = world) +
geom_sf() +
geom_text(data= world_points,aes(x=X, y=Y, label=name),
color = "darkblue", fontface = "bold", check_overlap = FALSE) +
annotate(geom = "text", x = -90, y = 26, label = "Gulf of Mexico",
fontface = "italic", color = "grey22", size = 6) +
coord_sf(xlim = c(-102.15, -74.12), ylim = c(7.65, 33.97), expand = FALSE)
ggplot(data = world) + geom_sf(fill= “antiquewhite”) + geom_text(data= world_points,aes(x=X, y=Y, label=name), color = “darkblue”, fontface = “bold”, check_overlap = FALSE) + annotate(geom = “text”, x = -90, y = 26, label = “Gulf of Mexico”, fontface = “italic”, color = “grey22”, size = 6) + annotation_scale(location = “bl”, width_hint = 0.5) + annotation_north_arrow(location = “bl”, which_north = “true”, pad_x = unit(0.75, “in”), pad_y = unit(0.5, “in”), style = north_arrow_fancy_orienteering) + coord_sf(xlim = c(-102.15, -74.12), ylim = c(7.65, 33.97), expand = FALSE) + xlab(“Longitude”) + ylab(“Latitude”) + ggtitle(“Map of the Gulf of Mexico and the Caribbean Sea”) + theme(panel.grid.major = element_line(color = gray(.5), linetype = “dashed”, size = 0.5), panel.background = element_rect(fill = “aliceblue”))
ggplot(data = world) + geom_sf(fill= “antiquewhite”) +
geom_text(data= world_points,aes(x=X, y=Y, label=name),
color = “darkblue”, fontface = “bold”,
check_overlap = FALSE) +
annotate(geom = “text”, x = -90, y = 26,
label = “Gulf of Mexico”, fontface = “italic”,
color = “grey22”, size = 6) +
annotation_scale(location = “bl”, width_hint = 0.5) +
annotation_north_arrow(location = “bl”,
which_north = “true”,
pad_x = unit(0.75, “in”),
pad_y = unit(0.5, “in”),
style = north_arrow_fancy_orienteering) + coord_sf(xlim = c(-102.15, -74.12), ylim = c(7.65, 33.97), expand = FALSE) + xlab(“Longitude”) + ylab(“Latitude”) + ggtitle(“Map of the Gulf of Mexico and the Caribbean Sea”) + theme(panel.grid.major = element_line(color = gray(.5), linetype = “dashed”, size = 0.5), panel.background = element_rect(fill = “aliceblue”))
ggplot(data = world) + geom_sf(fill= “antiquewhite”) +
geom_text(data= world_points,aes(x=X, y=Y, label=name),
color = “darkblue”, fontface = “bold”,
check_overlap = FALSE) +
annotate(geom = “text”, x = -90, y = 26,
label = “Gulf of Mexico”, fontface = “italic”,
color = “grey22”, size = 6) +
annotation_scale(location = “bl”, width_hint = 0.5) +
annotation_north_arrow(location = “bl”,
which_north = “true”,
pad_x = unit(0.75, “in”),
pad_y = unit(0.5, “in”),
style = north_arrow_fancy_orienteering) +
coord_sf(xlim = c(-102.15, -74.12),
ylim = c(7.65, 33.97), expand = FALSE) +
xlab(“Longitude”) + ylab(“Latitude”) +
ggtitle(“Map of the Gulf of Mexico and the Caribbean Sea”) +
theme(panel.grid.major = element_line(color = gray(.5),
linetype = “dashed”,
size = 0.5))
library(LearnBayes)
?pbetap
library(LearnBayes)
logpost1 <- function(p, y, n, a, b){
dbinom(y, prob = p, size = n, log = TRUE) +
dbeta(p, a, b, log = TRUE)
}
a <- 5; b <- 10; n <- 20; y <- 8
pbetap(c(a, b), n, y)
exp(laplace(logpost1, 0.5, y, n, a, b)$int)
library(readr)
TR_steps <- read_csv("Dropbox/COURSES FALL 2019/BAYES/TR_steps.csv")
View(TR_steps)
TR_steps$Steps
hist(TR_steps$Steps)
dotplot(TR_steps$Steps)
dplot(TR_steps$Steps)
ggplot(TR_steps, aes(Day, Steps)) + geom_points()
library(ggplot2)
ggplot(TR_steps, aes(Day, Steps)) + geom_points()
ggplot(TR_steps, aes(Day, Steps)) + geom_point()
mean(TR_steps$Steps)
sd(TR_steps$Steps)
library(dplyr)
TR_steps %>% group_by(Day) %>% summarize(M = mean(Steps))
?bayes.model.selection
mytext <- c("i am going to illustrate using",
"the tidytext package")
library(tidytext)
"the tidytext package")0
mytext <- data frame(Line = c("i am going to illustrate using",
"the tidytext package"))
mytext <- data frame(Line = c("i am going to illustrate using",
"the tidytext package"))
mytext <- data frame(Line = c("i am going to illustrate using",
mytext <- data frame(Line = c("i am going to illustrate using",
"the tidytext package"))
c("i am going to illustrate using",
"the tidytext package")
mytext <- data frame(Line = c("i am going to illustrate using",
"the tidytext package"))
mytext <- data.frame(Line =
c("i am going to illustrate using",
"the tidytext package"))
mytext
mytext %>%
unnest_tokens(word, Line)
library(tidyverse)
library(tidytext)
mytext %>%
unnest_tokens(word, Line)
names(mytext)
?unnest_tokens
mytext %>%
unnest_tokens(word, Line)
str(mytext)
mytext <- tibble(Line =
c("i am going to illustrate using",
"the tidytext package"))
mytext
mytext %>%
unnest_tokens(word, Line)
setwd("~/Dropbox/COURSES FALL 2019/3430")
dir()
mytext <- read_lines("mlk_speech.txt")
mytext
mytext %>%
unnest_tokens(word, Line) -> words_df
mytext <- read_lines("mlk_speech.txt") %>% as.tibble()
mytext <- read_lines("mlk_speech.txt") %>% as_tibble()
head(mytext)
mytext %>%
unnest_tokens(word, Line) -> words_df
mytext %>%
unnest_tokens(word, value) -> words_df
head(words_df)
words_df %>% group_by(word) %>% count() %>%
arrange(desc(n)) -> summ_words
head(words_df)
head(summ_words)
knitr::opts_chunk$set(echo = TRUE,
warning = FALSE,
message = FALSE)
words_df %>% anti_join(get_stopwords()) ->  words_df
words_df %>% group_by(word) %>% count() %>%
arrange(desc(n)) -> summ_words
head(summ_words)
library(wordcloud)
library(wordcloud)
wordcloud(summ_words)
?wordcloud
library(wordcloud)
wordcloud(summ_words$word, summ_words$n)
setwd("~/Dropbox/2019 WORK/Prob_Bayes_Solutions")
setwd("~/Dropbox/BAYES BOOK/FINAL CODE & DATA/chapter 12/scripts")
knitr::opts_chunk$set(echo = TRUE,
message = FALSE,
warning = FALSE)
library(ProbBayes)
library(runjags)
## write the model
modelString <-"
model {
## sampling
for (i in 1:N){
y[i] ~ dnorm(beta0 + beta1*x_years[i] +
beta2*x_gender[i], invsigma2)
}
## priors
beta0 ~ dnorm(mu0, g0)
beta1 ~ dnorm(mu1, g1)
beta2 ~ dnorm(mu2, g2)
invsigma2 ~ dgamma(a, b)
sigma <- sqrt(pow(invsigma2, -1))
}
"
y <- as.vector(ProfessorSalary$salary)
x_years <- as.vector(ProfessorSalary$yrs.service)
ProfessorSalary$gender <- ifelse(ProfessorSalary$sex == "Male", 1, 0)
x_gender <- as.vector(ProfessorSalary$gender)
N <- length(y)
the_data <- list("y" = y, "x_years" = x_years,
"x_gender" = x_gender, "N" = N,
"mu0" = 0, "g0" = 0.0025,
"mu1" = 0, "g1" = 0.0025,
"mu2" = 0, "g2" = 0.0025,
"a" = 0.001, "b" = 0.001)
posterior <- run.jags(modelString,
n.chains = 1,
data = the_data,
monitor = c("beta0", "beta1",
"beta2", "sigma"),
adapt = 1000,
burnin = 5000,
sample = 20000,
inits = initsfunction)
posterior <- run.jags(modelString,
n.chains = 1,
data = the_data,
monitor = c("beta0", "beta1",
"beta2", "sigma"),
adapt = 1000,
burnin = 5000,
sample = 20000)
posterior <- run.jags(modelString,
n.chains = 1,
data = the_data,
monitor = c("beta0", "beta1",
"beta2", "sigma"),
adapt = 1000,
burnin = 5000,
sample = 10000)
head(posterior)
posterior %>%
as.mcmc() %>%
as.data.frame() -> post
head(post)
mean_female_10 <- post[, "beta0"] +
post[, "beta1"] * 10
quantile(mean_female_10, c(0.05, 0.95))
summary(ProfessorSalary)
names(ProfessorSalary)
lm(salary ~ yrs.service + gender, data = ProfessorSalary) -> myfit
summarize(myfit)
myfit
summary(myfit)
summary(posterior)
mean_male_10 <- post[, "beta0"] +
post[, "beta1"] * 10 + post[, "beta2"]
quantile(mean_male_10, c(0.05, 0.95))
head(olympic_butterfly)
## write the model
modelString <-"
model {
## sampling
for (i in 1:N){
y[i] ~ dnorm(beta0 + beta1*x_year[i] +
beta2*x_gender[i], invsigma2)
}
## priors
beta0 ~ dnorm(mu0, g0)
beta1 ~ dnorm(mu1, g1)
beta2 ~ dnorm(mu2, g2)
invsigma2 ~ dgamma(a, b)
sigma <- sqrt(pow(invsigma2, -1))
}
"
y <- as.vector(olympic_butterfly$Time)
x_year <- as.vector(olympic_butterfly$Year) - 1964
olympic_butterfly$gender <-
ifelse(ProfessorSalary$Gender == "Female", 1, 0)
y <- as.vector(olympic_butterfly$Time)
x_year <- as.vector(olympic_butterfly$Year) - 1964
olympic_butterfly$gender <-
ifelse(olympic_butterfly$Gender == "Female", 1, 0)
x_gender <- as.vector(olympic_butterfly$gender)
N <- length(y)
the_data <- list("y" = y, "x_year" = x_year,
"x_gender" = x_gender, "N" = N,
"mu0" = 0, "g0" = 0.0025,
"mu1" = 0, "g1" = 0.0025,
"mu2" = 0, "g2" = 0.0025,
"a" = 0.001, "b" = 0.001)
posterior <- run.jags(modelString,
n.chains = 1,
data = the_data,
monitor = c("beta0", "beta1",
"beta2", "sigma"),
adapt = 1000,
burnin = 5000,
sample = 10000)
posterior %>%
as.mcmc() %>%
as.data.frame() -> post
summary(posterior)
olympic_butterfly
ytilde <-  rnorm(10000, post[, "beta0"] +
post[, "beta1"] * xyear +
post[, "beta2"] * gender,
post[, "sigma"])
ytilde <-  rnorm(10000, post[, "beta0"] +
post[, "beta1"] * x_year +
post[, "beta2"] * gender,
post[, "sigma"])
dim(post)
str(gender)
ytilde <-  rnorm(10000, post[, "beta0"] +
post[, "beta1"] * x_year +
post[, "beta2"] * x_gender,
post[, "sigma"])
one_residual <- function(i){
ytilde <-  rnorm(10000, post[, "beta0"] +
post[, "beta1"] * x_year[i] +
post[, "beta2"] * x_gender[i],
post[, "sigma"])
y[i] - quantile(ytilde, c(0.05, 0.95))
}
t(sapply(1:N, one_residual))
dim(olympic_butterfly)
length(x_year)
length(x_gender)
length(y)
y
View(olympic_butterfly)
one_residual <- function(i){
ytilde <-  rnorm(10000, post[, "beta0"] +
post[, "beta1"] * x_year[i] +
post[, "beta2"] * x_gender[i],
post[, "sigma"])
y[i] - quantile(ytilde, c(0.05, 0.95))
}
t(sapply(1:N, one_residual))
logpost.M1 <- function(theta, data){
RJ <- theta[1]
RA <- theta[2]
y1 <- data[1]
y2 <- data[2]
loglike <- dpois(y1, RJ, log = TRUE) +
dpois(y2, RA, log = TRUE)
logprior <- dgamma(RJ, shape = 240,
rate = 4, log = TRUE) +
dgamma(RA, shape = 200, rate = 4,log = TRUE)
return(loglike + logprior)
}
logpost.M2 <- function(theta, data){
R <- theta
y1 <- data[1]
y2 <- data[2]
loglike <- dpois(y1, R, log=TRUE) + dpois(y2, R, log=TRUE)
logprior <- dgamma(R, shape = 220, rate = 4,log = TRUE)
return(loglike + logprior)
}
logf.M1 <- laplace(logpost.M1, c(60, 60), c(66, 48))$int
logf.M2 <- laplace(logpost.M2, 60, c(66,48))$int
(BF <- exp(logf.M1 - logf.M2))
y <- c(8, 4, 5, 12, 5, 7, 10, 5, 12, 9, 8, 7, 19, 11, 7)
n <- c(15, 10, 7, 19, 11, 17, 19, 14, 23,
18, 24, 23, 26, 23, 16)
data <- cbind(y, n)
K <- c(10, 20, 50, 100)
lBF <- 0 * K
for (j in 1 : 4){
lBF[j] <- laplace(bfexch, 0,
list(data = data, K =K[j]))$int
}
cbind(K, lBF)
data(achievement)
attach(achievement)
bayes.model.selection(read1, cbind(Gen , Age, IQ),
c = 100, constant = FALSE)
bayes.model.selection(read1, cbind(Gen , Age, IQ),
c = 10, constant = FALSE)
bayes.model.selection(read1, cbind(Gen , Age, IQ),
c = 1000, constant = FALSE)
